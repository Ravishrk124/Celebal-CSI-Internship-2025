# 📘 Week 6 – Model Training & Hyperparameter Tuning 🔍

## 📌 Objective

Train multiple machine learning models and evaluate them using classification metrics. Apply hyperparameter tuning using `GridSearchCV` and `RandomizedSearchCV` to identify the best-performing model.

---

## ✅ Topics Covered

- Classification models: SVM, Logistic Regression, Decision Tree, Random Forest
- Evaluation metrics: Accuracy, Precision, Recall, F1 Score
- Cross-validation techniques
- Hyperparameter tuning using:
  - GridSearchCV (Exhaustive search)
  - RandomizedSearchCV (Efficient random sampling)
- Model selection based on evaluation scores

---

## 📁 Files Included

- `week6_model_training.py`: Python code with model training, evaluation, and tuning  
- `week6_results.png`: Screenshot of comparison table (optional)  
- `best_model_output.txt`: Model evaluation report with metrics

---

## 🧠 Key Takeaways

- Learned how to compare multiple models effectively using scikit-learn
- Understood the importance of choosing optimal hyperparameters
- Got hands-on experience with tuning tools like GridSearchCV and RandomizedSearchCV
- Practiced making data-driven decisions to select the best model

---

## 📆 Submission Details

- **Assignment Name:** Model Evaluation & Tuning
- **Week:** 6
- **Deadline:** July XX, 2025
- **Status:** ⏳ In Progress / ✅ Submitted

---

## 📚 Resources

- [KDnuggets – GridSearchCV vs RandomizedSearchCV](https://www.kdnuggets.com/hyperparameter-tuning-gridsearchcv-and-randomizedsearchcv-explained)
